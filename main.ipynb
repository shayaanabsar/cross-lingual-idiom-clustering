{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:30:56.591807Z",
     "iopub.status.busy": "2023-07-07T19:30:56.590557Z",
     "iopub.status.idle": "2023-07-07T19:31:01.449955Z",
     "shell.execute_reply": "2023-07-07T19:31:01.448900Z",
     "shell.execute_reply.started": "2023-07-07T19:30:56.591738Z"
    },
    "id": "h6WigLZWPURc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (4.21.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (1.12.1+cu116)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.13.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (1.23.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (5.9.4)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (3.19.6)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (3.1.30)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (2.3)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (66.1.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 3)) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 3)) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch import nn\n",
    "import torch\n",
    "import csv\n",
    "from random import choice\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:01.452590Z",
     "iopub.status.busy": "2023-07-07T19:31:01.452313Z",
     "iopub.status.idle": "2023-07-07T19:31:01.466582Z",
     "shell.execute_reply": "2023-07-07T19:31:01.465018Z",
     "shell.execute_reply.started": "2023-07-07T19:31:01.452557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:01.469229Z",
     "iopub.status.busy": "2023-07-07T19:31:01.468738Z",
     "iopub.status.idle": "2023-07-07T19:31:06.914443Z",
     "shell.execute_reply": "2023-07-07T19:31:06.913379Z",
     "shell.execute_reply.started": "2023-07-07T19:31:01.469188Z"
    },
    "id": "1cP8UKxkPURd",
    "outputId": "1bc8381b-cf0c-484f-8ded-88d23c1648c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14673, 24])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "translation_clusters = {}\n",
    "idioms = set()\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "with open('dataset.csv') as f:\n",
    "\treader = csv.DictReader(f)\n",
    "\tfor row in reader:\n",
    "\t\tidiom = row['english']\n",
    "\t\ttranslation = row['german']\n",
    "\t\tidioms.add(idiom)\n",
    "\t\tidioms.add(translation)\n",
    "\n",
    "\t\tif idiom in translation_clusters:\n",
    "\t\t\ttranslation_clusters[idiom].add(translation)\n",
    "\t\telse:\n",
    "\t\t\ttranslation_clusters[idiom] = {translation}\n",
    "\n",
    "\t\tif translation in translation_clusters:\n",
    "\t\t\ttranslation_clusters[translation].add(idiom)\n",
    "\t\telse:\n",
    "\t\t\ttranslation_clusters[translation] = {idiom}\n",
    "\n",
    "# Convert idioms to tokenized representations\n",
    "max_length = 0\n",
    "encoder = {}\n",
    "\n",
    "for idiom in idioms:\n",
    "\tencoded = tokenizer(idiom, return_tensors='pt', padding=True, truncation=True).input_ids\n",
    "\tmax_length = max(max_length, encoded.shape[1])\n",
    "\tencoder[idiom] = encoded\n",
    "\n",
    "num_idioms = len(idioms)\n",
    "decoder = {}\n",
    "\n",
    "# Generate idiom tensor\n",
    "idiom_tensor = torch.zeros(size=(num_idioms, max_length), dtype=torch.long)\n",
    "for i, idiom in enumerate(idioms):\n",
    "\tencoded = encoder[idiom]\n",
    "\tidiom_tensor[i, :encoded.shape[1]] = encoded[0]\n",
    "\tencoder[idiom] = idiom_tensor[i]\n",
    "\tdecoder[tuple(idiom_tensor[i].tolist())] = idiom\n",
    "\n",
    "assert decoder[tuple(encoder['makes me feel like'].tolist())] == 'makes me feel like'\n",
    "\n",
    "# Convert idiom clusters to tokenized representations\n",
    "translation_clusters_tokenized = {}\n",
    "for idiom in translation_clusters:\n",
    "\ttranslation_clusters_tokenized[tuple(encoder[idiom].tolist())] = set()\n",
    "\tfor match in translation_clusters[idiom]:\n",
    "\t\tif tuple(encoder[match].tolist()) == tuple(encoder[idiom].tolist()): continue\n",
    "\t\ttranslation_clusters_tokenized[tuple(encoder[idiom].tolist())].add(tuple(encoder[match].tolist()))\n",
    "\n",
    "# Print the shape of idiom_tensor\n",
    "print(idiom_tensor.shape)\n",
    "\n",
    "translation_clusters = translation_clusters_tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:06.916864Z",
     "iopub.status.busy": "2023-07-07T19:31:06.916331Z",
     "iopub.status.idle": "2023-07-07T19:31:06.926197Z",
     "shell.execute_reply": "2023-07-07T19:31:06.924488Z",
     "shell.execute_reply.started": "2023-07-07T19:31:06.916822Z"
    },
    "id": "q3aT53B7PURe"
   },
   "outputs": [],
   "source": [
    "train = idiom_tensor[:int(0.9*num_idioms)]\n",
    "test = idiom_tensor[int(0.9*num_idioms):int(0.95*num_idioms)]\n",
    "val = idiom_tensor[int(0.95*num_idioms):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:32:50.837312Z",
     "iopub.status.busy": "2023-07-07T19:32:50.836885Z",
     "iopub.status.idle": "2023-07-07T19:32:51.446579Z",
     "shell.execute_reply": "2023-07-07T19:32:51.445270Z",
     "shell.execute_reply.started": "2023-07-07T19:32:50.837284Z"
    },
    "id": "cKFBxmbOPURe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20230707_224137-kvld180i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/shayaan-absar/Cross-Lingual-Idiom-Sense-Clustering/runs/kvld180i\" target=\"_blank\">rosy-vortex-14</a></strong> to <a href=\"https://wandb.ai/shayaan-absar/Cross-Lingual-Idiom-Sense-Clustering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/shayaan-absar/Cross-Lingual-Idiom-Sense-Clustering/runs/kvld180i?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd4cc3f8df0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dimensions = 100\n",
    "device = 'cuda'\n",
    "iterations = 100\n",
    "learning_rate = 0.05\n",
    "batch_size = 16\n",
    "batch_accumulation = 2\n",
    "\n",
    "wandb.init(\n",
    "\tproject=\"Cross-Lingual-Idiom-Sense-Clustering\",\n",
    "\t\n",
    "\t# track hyperparameters and run metadata\n",
    "\tconfig={\n",
    "\t\"learning_rate\": learning_rate,\n",
    "\t\"architecture\": \"BERT\",\n",
    "\t\"batch_size\": batch_size*batch_accumulation*2,\n",
    "\t\"epochs\": iterations,\n",
    "\t\"embedding_dimensions\":latent_dimensions,\n",
    "\t}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.595736Z",
     "iopub.status.busy": "2023-07-07T19:31:18.594621Z",
     "iopub.status.idle": "2023-07-07T19:31:18.601770Z",
     "shell.execute_reply": "2023-07-07T19:31:18.600718Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.595701Z"
    },
    "id": "ekZ5dy91PURe"
   },
   "outputs": [],
   "source": [
    "def tensor_to_set(tensor):\n",
    "\treturn {tuple(d.tolist()) for d in tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.604409Z",
     "iopub.status.busy": "2023-07-07T19:31:18.603228Z",
     "iopub.status.idle": "2023-07-07T19:31:18.712110Z",
     "shell.execute_reply": "2023-07-07T19:31:18.710491Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.604367Z"
    },
    "id": "RfR89UMhPURe",
    "outputId": "468a1046-91d5-4095-d92d-b6d03eedf8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 24])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data):\n",
    "\tindexes = torch.randint(0, len(data), (batch_size,))\n",
    "\tbatch = set()\n",
    "\tset_data = tensor_to_set(data)\n",
    "\n",
    "\tfor i in indexes:\n",
    "\t\tidiom = data[i]\n",
    "\n",
    "\t\tpossible_idioms = set_data.intersection(translation_clusters[tuple(idiom.tolist())])\n",
    "\n",
    "\t\tif len(possible_idioms) == 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tassert not(tuple(idiom.tolist()) in possible_idioms)\n",
    "\n",
    "\t\trandom_cluster_mate = choice(list(possible_idioms))\n",
    "\t\tbatch.add(tuple(random_cluster_mate))\n",
    "\t\tbatch.add(tuple(idiom.tolist()))\n",
    "\n",
    "\tbatch = torch.tensor([list(x) for x in list(batch)]).to(device)\n",
    "\treturn batch\n",
    "\n",
    "print(get_batch(train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.714224Z",
     "iopub.status.busy": "2023-07-07T19:31:18.713797Z",
     "iopub.status.idle": "2023-07-07T19:31:18.724347Z",
     "shell.execute_reply": "2023-07-07T19:31:18.722506Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.714184Z"
    },
    "id": "FooH8tw8PURe"
   },
   "outputs": [],
   "source": [
    "def get_positive_sample(data):\n",
    "\tpositive_samples = []\n",
    "\n",
    "\tfor anchor in data:\n",
    "\t\tpossible_positive = translation_clusters[tuple(anchor.tolist())].intersection(tensor_to_set(data))\n",
    "\n",
    "\n",
    "\t\tchosen = torch.tensor(choice(list(possible_positive)))\n",
    "\t\tpositive_samples.append(chosen)\n",
    "\n",
    "\tpositive_samples = torch.stack(positive_samples).to(device)\n",
    "\n",
    "\treturn positive_samples\n",
    "\n",
    "\n",
    "def get_negative_sample(data):\n",
    "\tnegative_samples = []\n",
    "\n",
    "\tfor anchor in data:\n",
    "\t\tpossible_negative = tensor_to_set(data).difference(translation_clusters[tuple(anchor.tolist())])\n",
    "\n",
    "\t\tchosen = torch.tensor(choice(list(possible_negative)))\n",
    "\t\tnegative_samples.append(chosen)\n",
    "\n",
    "\tnegative_samples = torch.stack(negative_samples).to(device)\n",
    "\n",
    "\treturn negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.726321Z",
     "iopub.status.busy": "2023-07-07T19:31:18.725861Z",
     "iopub.status.idle": "2023-07-07T19:31:18.735947Z",
     "shell.execute_reply": "2023-07-07T19:31:18.734702Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.726286Z"
    },
    "id": "anrHVnxyPURe"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\tdef __init__(self, pooling):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.pooling = pooling\n",
    "\t\tself.roberta = AutoModelForMaskedLM.from_pretrained('xlm-roberta-base')\n",
    "\t\tself.output_layer = nn.Linear(250002, latent_dimensions)\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tinput_ids = torch.tensor(input, dtype=torch.long).to(device)\n",
    "\t\tattention_mask = torch.LongTensor(torch.ones(input.shape, dtype=torch.long)).to(device)\n",
    "\t\troberta_logits = self.roberta(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\t\tif self.pooling == 'average': pooled = torch.mean(roberta_logits, dim=0)\n",
    "\t\tvector_representation = self.output_layer(pooled)\n",
    "\n",
    "\t\treturn vector_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.737933Z",
     "iopub.status.busy": "2023-07-07T19:31:18.737552Z",
     "iopub.status.idle": "2023-07-07T19:31:25.746753Z",
     "shell.execute_reply": "2023-07-07T19:31:25.745615Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.737897Z"
    },
    "id": "meFKOyz6PURf"
   },
   "outputs": [],
   "source": [
    "model = Model(pooling='average')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:32:54.584387Z",
     "iopub.status.busy": "2023-07-07T19:32:54.584012Z",
     "iopub.status.idle": "2023-07-07T19:33:19.197930Z",
     "shell.execute_reply": "2023-07-07T19:33:19.196281Z",
     "shell.execute_reply.started": "2023-07-07T19:32:54.584357Z"
    },
    "id": "8TnNErnoPURf",
    "outputId": "655c6133-f8b5-4f31-8549-2ee708e16338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size=~64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/1296365142.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf3a944ed43450884f0ded7dfa9f1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▄▅▄▅▄▄▄▃▄▂▄▅▅▃▅▅▄▅▅▄▃▄▃▄▄▄▄▄▅▁▂▁▃█▁▅▄▇▅▅</td></tr><tr><td>val_loss</td><td>▅▁▄▄▆▇█▂▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.99805</td></tr><tr><td>val_loss</td><td>0.91751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-vortex-14</strong>: <a href=\"https://wandb.ai/shayaan-absar/Cross-Lingual-Idiom-Sense-Clustering/runs/kvld180i\" target=\"_blank\">https://wandb.ai/shayaan-absar/Cross-Lingual-Idiom-Sense-Clustering/runs/kvld180i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_224137-kvld180i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "triplet_loss = nn.TripletMarginLoss()\n",
    "\n",
    "def pass_batch(batch):\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\tpositive_samples = get_positive_sample(batch)\n",
    "\tnegative_samples = get_negative_sample(batch)\n",
    "\n",
    "\tencodings = model(batch)\n",
    "\tpositive_sample_encodings = model(positive_samples)\n",
    "\tnegative_sample_encodings = model(negative_samples)\n",
    "\n",
    "\treturn triplet_loss(encodings, positive_sample_encodings, negative_sample_encodings)\n",
    "\n",
    "print(f'Batch size=~{batch_size*batch_accumulation*2}')\n",
    "for i in range(iterations):\n",
    "\tloss = 0\n",
    "\tfor j in range(batch_accumulation):\n",
    "\t\tbatch = get_batch(train)\n",
    "\t\tloss += pass_batch(batch)\n",
    "\tloss /= batch_accumulation\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\n",
    "\tif i % 10 == 0:\n",
    "\t\tval_loss = pass_batch(get_batch(val))\n",
    "\t\twandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "\twandb.log({\"loss\": loss})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
