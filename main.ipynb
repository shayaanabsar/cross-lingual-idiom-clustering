{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:30:56.591807Z",
     "iopub.status.busy": "2023-07-07T19:30:56.590557Z",
     "iopub.status.idle": "2023-07-07T19:31:01.449955Z",
     "shell.execute_reply": "2023-07-07T19:31:01.448900Z",
     "shell.execute_reply.started": "2023-07-07T19:30:56.591738Z"
    },
    "id": "h6WigLZWPURc"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch import nn\n",
    "import torch\n",
    "import csv\n",
    "from random import choice\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:01.452590Z",
     "iopub.status.busy": "2023-07-07T19:31:01.452313Z",
     "iopub.status.idle": "2023-07-07T19:31:01.466582Z",
     "shell.execute_reply": "2023-07-07T19:31:01.465018Z",
     "shell.execute_reply.started": "2023-07-07T19:31:01.452557Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:01.469229Z",
     "iopub.status.busy": "2023-07-07T19:31:01.468738Z",
     "iopub.status.idle": "2023-07-07T19:31:06.914443Z",
     "shell.execute_reply": "2023-07-07T19:31:06.913379Z",
     "shell.execute_reply.started": "2023-07-07T19:31:01.469188Z"
    },
    "id": "1cP8UKxkPURd",
    "outputId": "1bc8381b-cf0c-484f-8ded-88d23c1648c5"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "translation_clusters = {}\n",
    "idioms = set()\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "with open('dataset.csv') as f:\n",
    "\treader = csv.DictReader(f)\n",
    "\tfor row in reader:\n",
    "\t\tidiom = row['english']\n",
    "\t\ttranslation = row['german']\n",
    "\t\tidioms.add(idiom)\n",
    "\t\tidioms.add(translation)\n",
    "\n",
    "\t\tif idiom in translation_clusters:\n",
    "\t\t\ttranslation_clusters[idiom].add(translation)\n",
    "\t\telse:\n",
    "\t\t\ttranslation_clusters[idiom] = {translation}\n",
    "\n",
    "\t\tif translation in translation_clusters:\n",
    "\t\t\ttranslation_clusters[translation].add(idiom)\n",
    "\t\telse:\n",
    "\t\t\ttranslation_clusters[translation] = {idiom}\n",
    "\n",
    "# Convert idioms to tokenized representations\n",
    "max_length = 0\n",
    "encoder = {}\n",
    "\n",
    "for idiom in idioms:\n",
    "\tencoded = tokenizer(idiom, return_tensors='pt', padding=True, truncation=True).input_ids\n",
    "\tmax_length = max(max_length, encoded.shape[1])\n",
    "\tencoder[idiom] = encoded\n",
    "\n",
    "num_idioms = len(idioms)\n",
    "decoder = {}\n",
    "\n",
    "# Generate idiom tensor\n",
    "idiom_tensor = torch.zeros(size=(num_idioms, max_length), dtype=torch.long)\n",
    "for i, idiom in enumerate(idioms):\n",
    "\tencoded = encoder[idiom]\n",
    "\tidiom_tensor[i, :encoded.shape[1]] = encoded[0]\n",
    "\tencoder[idiom] = idiom_tensor[i]\n",
    "\tdecoder[tuple(idiom_tensor[i].tolist())] = idiom\n",
    "\n",
    "assert decoder[tuple(encoder['makes me feel like'].tolist())] == 'makes me feel like'\n",
    "\n",
    "# Convert idiom clusters to tokenized representations\n",
    "translation_clusters_tokenized = {}\n",
    "for idiom in translation_clusters:\n",
    "\ttranslation_clusters_tokenized[tuple(encoder[idiom].tolist())] = set()\n",
    "\tfor match in translation_clusters[idiom]:\n",
    "\t\tif tuple(encoder[match].tolist()) == tuple(encoder[idiom].tolist()): continue\n",
    "\t\ttranslation_clusters_tokenized[tuple(encoder[idiom].tolist())].add(tuple(encoder[match].tolist()))\n",
    "\n",
    "# Print the shape of idiom_tensor\n",
    "print(idiom_tensor.shape)\n",
    "\n",
    "translation_clusters = translation_clusters_tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:06.916864Z",
     "iopub.status.busy": "2023-07-07T19:31:06.916331Z",
     "iopub.status.idle": "2023-07-07T19:31:06.926197Z",
     "shell.execute_reply": "2023-07-07T19:31:06.924488Z",
     "shell.execute_reply.started": "2023-07-07T19:31:06.916822Z"
    },
    "id": "q3aT53B7PURe"
   },
   "outputs": [],
   "source": [
    "train = idiom_tensor[:int(0.9*num_idioms)]\n",
    "test = idiom_tensor[int(0.9*num_idioms):int(0.95*num_idioms)]\n",
    "val = idiom_tensor[int(0.95*num_idioms):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:32:50.837312Z",
     "iopub.status.busy": "2023-07-07T19:32:50.836885Z",
     "iopub.status.idle": "2023-07-07T19:32:51.446579Z",
     "shell.execute_reply": "2023-07-07T19:32:51.445270Z",
     "shell.execute_reply.started": "2023-07-07T19:32:50.837284Z"
    },
    "id": "cKFBxmbOPURe"
   },
   "outputs": [],
   "source": [
    "latent_dimensions = 100\n",
    "device = 'cuda'\n",
    "iterations = 100\n",
    "learning_rate = 0.05\n",
    "batch_size = 16\n",
    "batch_accumulation = 2\n",
    "\n",
    "wandb.init(\n",
    "\tproject=\"Cross-Lingual-Idiom-Sense-Clustering\",\n",
    "\t\n",
    "\t# track hyperparameters and run metadata\n",
    "\tconfig={\n",
    "\t\"learning_rate\": learning_rate,\n",
    "\t\"architecture\": \"BERT\",\n",
    "\t\"batch_size\": batch_size*batch_accumulation*2,\n",
    "\t\"epochs\": iterations,\n",
    "\t\"embedding_dimensions\":latent_dimensions,\n",
    "\t}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.595736Z",
     "iopub.status.busy": "2023-07-07T19:31:18.594621Z",
     "iopub.status.idle": "2023-07-07T19:31:18.601770Z",
     "shell.execute_reply": "2023-07-07T19:31:18.600718Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.595701Z"
    },
    "id": "ekZ5dy91PURe"
   },
   "outputs": [],
   "source": [
    "def tensor_to_set(tensor):\n",
    "\treturn {tuple(d.tolist()) for d in tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.604409Z",
     "iopub.status.busy": "2023-07-07T19:31:18.603228Z",
     "iopub.status.idle": "2023-07-07T19:31:18.712110Z",
     "shell.execute_reply": "2023-07-07T19:31:18.710491Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.604367Z"
    },
    "id": "RfR89UMhPURe",
    "outputId": "468a1046-91d5-4095-d92d-b6d03eedf8b7"
   },
   "outputs": [],
   "source": [
    "def create_batch(data):\n",
    "\tindexes = torch.randint(0, len(data), (batch_size,))\n",
    "\tbatch = set()\n",
    "\tset_data = tensor_to_set(data)\n",
    "\n",
    "\tfor i in indexes:\n",
    "\t\tidiom = data[i]\n",
    "\n",
    "\t\tpossible_idioms = set_data.intersection(translation_clusters[tuple(idiom.tolist())])\n",
    "\n",
    "\t\tif len(possible_idioms) == 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tassert not(tuple(idiom.tolist()) in possible_idioms)\n",
    "\n",
    "\t\trandom_cluster_mate = choice(list(possible_idioms))\n",
    "\t\tbatch.add(tuple(random_cluster_mate))\n",
    "\t\tbatch.add(tuple(idiom.tolist()))\n",
    "\n",
    "\tbatch = torch.tensor([list(x) for x in list(batch)]).to(device)\n",
    "\n",
    "\treturn batch\n",
    "\n",
    "def get_batch(data):\n",
    "\tbatch = torch.tensor([])\n",
    "\n",
    "\twhile batch.numel() == 0:\n",
    "\t\tbatch = create_batch(data)\n",
    "\treturn batch\n",
    "\n",
    "print(get_batch(train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.714224Z",
     "iopub.status.busy": "2023-07-07T19:31:18.713797Z",
     "iopub.status.idle": "2023-07-07T19:31:18.724347Z",
     "shell.execute_reply": "2023-07-07T19:31:18.722506Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.714184Z"
    },
    "id": "FooH8tw8PURe"
   },
   "outputs": [],
   "source": [
    "def get_positive_sample(data):\n",
    "\tpositive_samples = []\n",
    "\n",
    "\tfor anchor in data:\n",
    "\t\tpossible_positive = translation_clusters[tuple(anchor.tolist())].intersection(tensor_to_set(data))\n",
    "\n",
    "\n",
    "\t\tchosen = torch.tensor(choice(list(possible_positive)))\n",
    "\t\tpositive_samples.append(chosen)\n",
    "\n",
    "\tpositive_samples = torch.stack(positive_samples).to(device)\n",
    "\n",
    "\treturn positive_samples\n",
    "\n",
    "\n",
    "def get_negative_sample(data):\n",
    "\tnegative_samples = []\n",
    "\n",
    "\tfor anchor in data:\n",
    "\t\tpossible_negative = tensor_to_set(data).difference(translation_clusters[tuple(anchor.tolist())])\n",
    "\n",
    "\t\tchosen = torch.tensor(choice(list(possible_negative)))\n",
    "\t\tnegative_samples.append(chosen)\n",
    "\n",
    "\tnegative_samples = torch.stack(negative_samples).to(device)\n",
    "\n",
    "\treturn negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.726321Z",
     "iopub.status.busy": "2023-07-07T19:31:18.725861Z",
     "iopub.status.idle": "2023-07-07T19:31:18.735947Z",
     "shell.execute_reply": "2023-07-07T19:31:18.734702Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.726286Z"
    },
    "id": "anrHVnxyPURe"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\tdef __init__(self, pooling):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.pooling = pooling\n",
    "\t\tself.roberta = AutoModelForMaskedLM.from_pretrained('xlm-roberta-base')\n",
    "\t\tself.batch_norm = nn.BatchNorm1d(24)\n",
    "\t\tself.output_layer = nn.Linear(250002, latent_dimensions)\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tinput_ids = torch.tensor(input, dtype=torch.long).to(device)\n",
    "\t\tattention_mask = torch.LongTensor(torch.ones(input.shape, dtype=torch.long)).to(device)\n",
    "\t\troberta_logits = self.roberta(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\t\troberta_logits = self.batch_norm(roberta_logits)\n",
    "\t\tif self.pooling == 'average': pooled = torch.mean(roberta_logits, dim=0)\n",
    "\t\tvector_representation = self.output_layer(pooled)\n",
    "\n",
    "\t\treturn vector_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T19:31:18.737933Z",
     "iopub.status.busy": "2023-07-07T19:31:18.737552Z",
     "iopub.status.idle": "2023-07-07T19:31:25.746753Z",
     "shell.execute_reply": "2023-07-07T19:31:25.745615Z",
     "shell.execute_reply.started": "2023-07-07T19:31:18.737897Z"
    },
    "id": "meFKOyz6PURf"
   },
   "outputs": [],
   "source": [
    "model = Model(pooling='average')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T19:32:54.584387Z",
     "iopub.status.busy": "2023-07-07T19:32:54.584012Z",
     "iopub.status.idle": "2023-07-07T19:33:19.197930Z",
     "shell.execute_reply": "2023-07-07T19:33:19.196281Z",
     "shell.execute_reply.started": "2023-07-07T19:32:54.584357Z"
    },
    "id": "8TnNErnoPURf",
    "outputId": "655c6133-f8b5-4f31-8549-2ee708e16338"
   },
   "outputs": [],
   "source": [
    "triplet_loss = nn.TripletMarginLoss()\n",
    "\n",
    "def pass_batch(batch):\n",
    "\ttorch.cuda.empty_cache()\n",
    "\tpositive_samples = get_positive_sample(batch)\n",
    "\tnegative_samples = get_negative_sample(batch)\n",
    "\n",
    "\tencodings = model(batch)\n",
    "\tpositive_sample_encodings = model(positive_samples)\n",
    "\tnegative_sample_encodings = model(negative_samples)\n",
    "\n",
    "\treturn triplet_loss(encodings, positive_sample_encodings, negative_sample_encodings)\n",
    "\n",
    "print(f'Batch size=~{batch_size*batch_accumulation*2}')\n",
    "for i in range(iterations):\n",
    "\ttorch.cuda.empty_cache()\n",
    "\tloss = 0\n",
    "\tfor j in range(batch_accumulation):\n",
    "\t\tbatch = get_batch(train)\n",
    "\t\tloss += pass_batch(batch)\n",
    "\tloss /= batch_accumulation\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\n",
    "\tif i % 10 == 0:\n",
    "\t\tval_loss = pass_batch(get_batch(val))\n",
    "\t\twandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "\twandb.log({\"loss\": loss})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
